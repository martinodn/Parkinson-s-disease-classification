---
title: "Parkinson Diseases"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Apriamo i dati

```{r}
rm(list = ls())
dati <- read.csv("~/Desktop/SMHDD/pd_speech_features.csv",header = T,skip = 1)
source("~/Desktop/SMHDD/lift-roc-tab.R")

```

Skippiamo la prima riga che è quella che contiene le macro categorie, adesso le recuperiamo:

```{r}
dati1 <- read.csv("~/Desktop/SMHDD/pd_speech_features.csv",header = F)
dati1 <- dati1[1,]
rm(dati1)
```

Le macro categorie delle variabili sono divise come:

```{r,include=FALSE}
dt <- cbind(c("3-23","24-26","27-30","31-34","35-56","57-140","141-322","323-755"),c("Baseline Feature","Intensity Parameters","Formant Frequencies","Bandwidth Parameters","Vocal Fold","MFCC","Wavelet Features","TQWT Features"))
colnames(dt) <- c("Colonne","Descrizione")

#install.packages("kableExtra")
# install.packages("xcolor")
# library(xcolor)
library(knitr)
library(kableExtra)

```
```{r,echo=F}
kable(dt, "latex", booktabs = T) %>% kable_styling(position = "center")
```


I gruppi sulle variabili non sono stati fatti tenendo conto dell'id che chiaramente andrà tolto prima di cominciare l'analisi, e di conseguenza i gruppi dovranno scalare di un numero.
La variabile enll'attuale posizione 2 è il genere.
In ogni caso i nomi delle variabili sono già assegnati ai colnames.

```{r}
head(colnames(dati))
```

Cominciamo rimuovendo l'id, non abbiamo dati mancanti quinid non abbiamo problemi di imputaizione etc.
Sistemiamo inoltre l'ordine e rinomianiamo la risposta, per comodità
```{r}
id <- dati[,1]
dati <- dati[,-1]
dati <- cbind(dati[grep("class",colnames(dati))],dati[-grep("class",colnames(dati))])
colnames(dati)[1] <- "y"

```
Mantengo comunque l'id non si sa mai ci venga voglia di fare un modello gerarchico.
Ho riinominato la risposta come "y" e l'ho spostata all'inizio, per due motivi:
1) Per me è più comodo
2) Le colonne delle macrocategorie rimangono invariate.

Indaghiamo la risposta per capire se ci troviamo in siutazione scomode, come classi sbilanciate:

```{r}

dati$y <- as.factor(dati$y)
dati$gender <- as.factor(dati$gender)
prop.table(table(dati$y))

```
Sono sblianciate, ma non troppo quindi si cercheremo di risolvere questo problema ma non dovrebbe essere un casino farlo.

Procediamo diviendendo in Stima-Verifica il dataset e costruendo la Model.matrix per poi girare qualche modellino:

```{r}
set.seed(69)
acaso <<- sample(1:nrow(dati), 0.75*nrow(dati))
sss <<- dati[acaso,]; vvv <<- dati[-acaso,]

```

Definisco la posizione della risposta, così in futuro non sbaglio, e vediamo quanto sbilanciata è la risposta nel insieme di Verifica.
```{r}
risposta <- 1
table(sss$y)/length(sss$y)
```
Come ci potevamo aspettare la proporzione (per fortuna) è coerente con il dataset, quindi possiamo porcedere a risolvere il problema dello sblianciamento dei dati definendo un cutoff.
Lo sbilanciamento della variabile risposta non è un problema a livello computazionale: i modelli possono essere stimati in qualunque caso. E' invece un problema a livello teorico/concettuale, che si manifesta in fase di analisi della qualità del modello: un classificatore che viene costruito su una variabile risposta con modalità sbilanciate rischia di assegnare troppo peso ad una delle modalità. 
La soluzione che proponiamo consiste nel selezionare un soglia corretta che separi la frontiera di classificazione: questa soglia verrà scelta (circa) pari alla minor frequenza della modalità della variabile risposta.
Procedendo con questo metodo si decide di assegnare un costo maggiore all’errata classificazione dell’**evento raro** piuttosto che quella dell’**evento più frequente**.
La soglia quindi la definiamo come:

```{r}
cutoff <- 0.2557319
```

Un altra alternativa sarebbe quella di bilanciare il dataset ma perderemmo il 75% dei dati.

A questo punto facciamo un paio di aggiustamenti, ovvero ci salviamo la risposta dell'insieme di stima e dell'insisme di verifica in forma numerica, ci serviranno dopo.
Poi definiamo l'oggetto formula che ci servirà per costruire le Model.matrix e per girare i modelli, una con la risposta quantitativa e una con la risposta come fattore:

```{r}
y_num <- as.numeric(sss$y)-1
#table(y_num)  # risposta quantitativa sull'insieme di stima 
g <- as.numeric(vvv$y)-1
#table(g)      # risposta quantitativa sull'insieme di verifica

f1 <- as.formula(paste("y ~ ", paste(names(sss)[-c(risposta)], collapse = "+"),
                       collapse = ""))
#f1 # risposta qualitativa

f2 <- as.formula(paste("y_num ~ ", paste(names(sss)[-c(risposta)], collapse = "+"), 
                       collapse = ""))
#f2 # risposta quantitativa

```

A questo punto non ci resta che trovarci la model.matrix nell'insieme di stima e verifica, normalizziamo le variabili perchè è meglio farlo.

```{r}
X.sss <- model.matrix(~., data = sss[,-risposta])[, -1] # SENZA INTERCETTA
X.vvv <- model.matrix(~., data = vvv[,-risposta])[, -1] # SENZA INTERCETTA

# standardizziamo le variabili quantitative, non sex e la risposta chiaramente
std.sss <- sss
for(i in 3:nrow(sss)){ std.sss[, i] <- scale(std.sss[, i])}
Xstd.sss <- model.matrix(~., data = std.sss[,-risposta])[, -1] # SENZA INTERCETTA
std.vvv <- vvv
for(i in 3:nrow(sss)){ std.vvv[, i] <- scale(std.vvv[, i])}
Xstd.vvv <- model.matrix(~., data = std.vvv[,-risposta])[, -1] # SENZA INTERCETTA
rm(std.sss, std.vvv)
```

A questo punto ci siamo creati le model.matrix dell'insieme di stima e di verifica sia standardizzata che non.

Definiamo una funzione che ci permetta poi di valutare l'accuratezza dei nostri modelli:

```{r}

table.summary <- function(previsti,reali,cutoff=NA){
  risultati <- list()
  if(!is.na(cutoff)){
    previsti <- previsti>cutoff
  }
  tab <- table(previsti,reali)
  accuracy <- sum(diag(tab))/sum(tab)
  errore <- 1-accuracy
  cat('Matrice di confusione\n')
  print(tab)
  cat('Accuratezza: ',accuracy,'\n')
  cat('Errore: ',errore,'\n')
  if(ncol(tab)==2){
    precision <- tab[2,2]/sum(tab[,2])
    recall <- tab[2,2]/sum(tab[2,])
    f1 <- 2*precision*recall/(precision+recall)
    
    cat('Precisione: ',precision,'\n')
    cat('Richiamo: ',recall,'\n')
    cat('F1: ',f1,'\n')
  }
  risultati <- list(matrice.confusione=tab,accuratezza=accuracy,errore=errore)
  if(ncol(tab)==2){
    risultati$precisione <- precision
    risultati$richiamo <- recall
    risultati$F1 <- f1
  }
  invisible(risultati)
}
```

Cominciamo quindi a fare qualche modellino, il primo che possiamo fare è il lasso logistico:

```{r}

library(glmnet)
fit <- glmnet(X.sss, sss$y, family = "binomial",standardize = T)
plot(fit, xvar="lambda", label=TRUE)

cfit <- cv.glmnet(X.sss, sss$y,standardize=T,family="binomial")
plot(cfit)

{
  plot(fit, xvar = "lambda")
  abline(v = log(cfit$lambda.min), col = "red", lty = "dashed")
  abline(v = log(cfit$lambda.1se), col = 3, lty = "dashed")
  legend("bottomright",legend=c("lambda.min","lambda.1se"),col=c(2,3),lty=c(2,2))
}

```


Facciamo entrambi i modelli sia quello scegliendo il lambda minimo che quello con lambda 1 S.E. abbiamo:
```{r}
p.fit.lambda.min <- predict(cfit, newx=X.vvv,s="lambda.min",type="response")
lr.lasso.logistico  <- lift.roc(p.fit.lambda.min, g, type = "crude", plot.it = FALSE)
table.summary(p.fit.lambda.min,vvv$y,cutoff)
```

e adesso proviamo quello con lambda 1 S.E.
```{r}
p.fit.lambda.1se <- predict(cfit, newx=X.vvv,s="lambda.1se",type="response")
lr.lasso.logistico  <- lift.roc(p.fit.lambda.1se, g, type = "crude", plot.it = FALSE)
table.summary(p.fit.lambda.1se,vvv$y,cutoff)
```

Il modello con lambda minimo semmbra complessivamente leggermente migliore rispetto a quello con lambda ad 1 standard error dal minimo.

Il prossimo modello che possiamo fare è un grouped lasso dove raggruppiamo i gruppi relativi alle macro-categorie definite all'inzio ovvero:

```{r}
dt
```

dobbiamo definire J (numero di gruppi) matrici Z (sottomatrice della x che comorende tutte le variabili che vogliamo raggruppare) rappresentante il j-esimo gruppo di variabili e il vettore dei coefficienti.
Il nostro obiettivo è quello di predirre y basandomi sulle $(Z_1,...,Z_J)$ covariate.

Quindi:

```{r, eval=F}

# group <- c(rep(1,1),rep(2,length(3:23)),rep(3,length(24:26)),
#            rep(4,length(27:30)),rep(5,length(31:34)),rep(6,length(35:56)),
#            rep(7,length(57:140)),rep(8,length(141:322)),rep(9,length(323:754)))
# 
# library(gglasso)
# 
# yy <- as.numeric(sss$y)-1
# yy[which(yy==0)] <- -1
# 
# fit.glasso <- gglasso(x = X.sss,y = yy,group = group,loss = "logit")
# #head(coef(fit.glasso))
# print(fit.glasso)
# {
#   par(mfrow=c(1,3))
#   plot(fit.glasso)              # plots the coefficients against the log-lambda sequence
#   plot(fit.glasso,group=TRUE)   # plots group norm against the log-lambda sequence
#   plot(fit.glasso,log.l=FALSE)  # plots against the lambda sequence
#   par(mfrow=c(1,1))
# }
# 
# 
# cv.fit.galsso <- cv.glasso(x = X.sss,y = yy,group = group,pred.loss = "misclass",nfolds = 5)
# #head(coef.cv.glasso(cv.fit.galsso))
# plot(cv.fit.galsso)
# 
# 
# lmbda=cv.fit.galsso$lambda.1se
# {
#   plot(fit.glasso)
#   abline(v=log(lmbda), lty=2, col=2)
# }
# 
# 
# 
# p.gglasso.lambda.min = predict(cv.fit.galsso$gglasso.fit, newx = X.vvv,s = cv.fit.galsso$lambda.min, type = "class")
# 
# table.summary(p.gglasso.lambda.min,vvv$y,cutoff)
# 
# p.gglasso.lambda.1se = predict(cv.fit.galsso$gglasso.fit, newx = X.vvv,s = cv.fit.galsso$lambda.1se, type = "class")
# 
# table.summary(p.gglasso.lambda.1se,vvv$y,cutoff)

```



Un altro cosa che potremmo fare è l'elastic net, i dati però come possiamo vedere **non** sono molto correlati tra loro quinidi non ha molto senso fare un Elastic Net:
```{r}

aa <- cor(sss[,-c(1:2)])
diag(aa) <- 0
correlazioni <-matrix(sapply(c(0.75,0.8,0.9,0.95,0.99),
                    function(x){(sum(abs(aa)>x)/2)/(nrow(aa)*(nrow(aa)-1)/2)}),nrow=1)
rm(aa)

colnames(correlazioni) <- c(0.75,0.8,0.9,0.95,0.99)
rownames(correlazioni) <- c("%")
```

```{r,echo=F}
kable(correlazioni, "latex", booktabs = T) %>% kable_styling(position = "center")
rm(correlazioni)
```

```{r}
gruppi <- matrix(c(3,23,24,26,27,30,31,34,35,56,57,140,141,322,323,754),ncol=2,byrow=2)

correlazioni_per_gruppi <- function(gruppi){
  correlazioni <- matrix(NA,ncol = 5,nrow = nrow(gruppi))
  for(i in 1:nrow(gruppi)){
    aa <- cor(sss[,c(gruppi[i,1]:gruppi[i,2])])
    diag(aa) <- 0
    cors <- sapply(c(0.75,0.8,0.9,0.95,0.99),function(x){(sum(abs(aa)>x)/2)/
                    (nrow(aa)*(nrow(aa)-1)/2)})
    correlazioni[i,] <- cors
  }
  colnames(correlazioni) <- c(0.75,0.8,0.9,0.95,0.99)
  rownames(correlazioni) <- c("% gruppo 1","% gruppo 2","% gruppo 3","% gruppo 4",
                              "% gruppo 5","% gruppo 6","% gruppo 7","% gruppo 8")
  return(correlazioni)
}


cors <- correlazioni_per_gruppi(gruppi)
```

```{r,echo=F}
kable(cors, "latex", booktabs = T) %>% kable_styling(position = "center")
rm(gruppi)
rm(cors)
```



Possiamo provare a farla lo stesso:

```{r}
grid <- seq(0.45,0.55,length=20)
acc <- rep(NA,20)
for(i in 1:20){
  cv <- cv.glmnet(X.sss, sss$y,standardize=T,family="binomial",alpha=0.5)
  pp <- predict(cv, newx=X.vvv,s="lambda.min",type="response")
  tt <- table.summary(pp,vvv$y,cutoff)
  acc[i] <- tt$errore
}
best.alpha <- grid[which.min(acc)]


fit.elastic.net <- glmnet(X.sss, sss$y, family = "binomial",standardize = T,alpha = best.alpha)
plot(fit.elastic.net, xvar="lambda", label=TRUE)

cv.fit.elastic.net <- cv.glmnet(X.sss, sss$y,standardize=T,family="binomial",alpha=best.alpha)
plot(cv.fit.elastic.net)

{
  plot(fit.elastic.net, xvar = "lambda")
  abline(v = log(cv.fit.elastic.net$lambda.min), col = "red", lty = "dashed")
  abline(v = log(cv.fit.elastic.net$lambda.1se), col = 3, lty = "dashed")
  legend("bottomright",legend=c("lambda.min","lambda.1se"),col=c(2,3),lty=c(2,2))
}
p.fit.lambda.min.elastic.net <- predict(cv.fit.elastic.net, newx=X.vvv,s="lambda.min",type="response")
lr.elastic.net  <- lift.roc(p.fit.lambda.min.elastic.net, g, type = "crude", plot.it = FALSE)
table.summary(p.fit.lambda.min.elastic.net,vvv$y,cutoff)

```

```{r}

p.fit.lambda.1se.elastic.net <- predict(cv.fit.elastic.net, newx=X.vvv,s="lambda.1se",type="response")
lr.elastic.net.1se  <- lift.roc(p.fit.lambda.1se.elastic.net, g, type = "crude", plot.it = FALSE)
table.summary(p.fit.lambda.1se.elastic.net,vvv$y,cutoff)

```



Facciamo le Sparse Support Vector machines con lasso penalty:

```{r}
library(sparseSVM)
bilanciamento<-function(dati, categoria=sss$y){
  K<-length(levels(categoria))
  livelli<-levels(categoria)
  l<-vector('list',K)
  new<-NULL
  for ( i in 1:K){
    l[[i]]<-sample(1:table(categoria)[i], min(table(categoria)))
    new<-rbind(new, dati[categoria==livelli[i],][l[[i]],] )
  }
  return(new)
}
sss1 <- bilanciamento(sss)
X.sss1 <- model.matrix(~., data = sss1[,-risposta])[, -1] # SENZA INTERCETTA

yy1 <- as.numeric(sss1$y)-1
yy1[which(yy1==0)] <- -1

lasso.svm <- sparseSVM(X = X.sss1, y = yy1,alpha = 1)

plot(lasso.svm, xvar="lambda",ylim=c(-1000,1000))
#
cv.svm <- cv.sparseSVM(X.sss1,yy1,nfolds = 10,preprocess="standardize")

{
  par(mfrow=c(1,2))
  plot(cv.svm)
  abline(v=log(cv.svm$lambda.min),col=3,lty=3)

  plot(lasso.svm,ylim=c(-1000,1000))
  abline(v = log(cv.svm$lambda.min), col = 3, lty =3)
  par(mfrow=c(1,1))
}

p.lasso.svm <- predict(object = cv.svm,X = X.vvv,type = "class")


gg <- as.numeric(vvv$y)-1
gg[which(gg==0)] <- -1

table.summary(p.lasso.svm,gg)

```


e adesso proviamo le Sparse Support Vector machines con Elastic Net penalty:

```{r}

elastic.svm <- sparseSVM(X = X.sss1, y = yy1,alpha = 0.5)
plot(elastic.svm, xvar="lambda",ylim=c(-500,500))
#
cv.svm.elastic <- cv.sparseSVM(X.sss1,yy1,nfolds = 10,preprocess="standardize",alpha=0.5)

{
  par(mfrow=c(1,2))
  plot(cv.svm.elastic)
  abline(v=log(cv.svm.elastic$lambda.min),col=3,lty=3)

  plot(elastic.svm,ylim=c(-500,500))
  abline(v = log(cv.svm.elastic$lambda.min), col = 3, lty =3)
  par(mfrow=c(1,1))
}

p.elastic.svm <- predict(object = cv.svm.elastic,X = X.vvv,type = "class")

table.summary(p.elastic.svm,gg)

```






**ALTRE IDEE:**

**- Relaxed lasso** percè dicono sia uno dei modi migliori per stimare il modello logit

**- SPAM**

**- modello gerarchico maschi femmine**

**- SpPCA -> modelli vari tipo RF o BOOSTING**

**- SVM**

** Possiamo se no fare un lasso adattivo e usare le variabili che questo seleziona per girare altri modelli**

Alla fine confrontiamo tutt'cose.













# memorandum per come si usa lift_roc papapa
```{r}
#a <- rbind(lr.lasso.logistico,lr.lasso.logistico)
#confronto_lift_roc(a,type=1)
```

